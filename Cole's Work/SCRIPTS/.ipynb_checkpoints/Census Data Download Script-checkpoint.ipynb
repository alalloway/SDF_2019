{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census Data Download Script\n",
    "This script is for downloading the specified file directories from the US Census Geo-Tiger FTP Site. Please note that this script must be run in Anaconda's Jupyter Lab, not the ArcPro Jupyter Lab, in order to successfully import all modules.\n",
    "\n",
    "Users must specify the correct local file directory to reposit the downloaded data. This script will automatically create folders within the specified file directory, into which the data will be downloaded and unzipped. \n",
    "\n",
    "Users must also specificy the url they want to download from - this script assumes 2018 TIGER, but can be changed to any year available from Census FTP: https://www2.census.gov/geo/tiger/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io, csv, os\n",
    "from bs4 import BeautifulSoup\n",
    "from zipfile import BadZipfile\n",
    "\n",
    "\n",
    "# Where you want the files to download to (will create new folders within this workspace) \n",
    "theShapeFileDirectory = r\"C:\\Users\\allow001\\work\\BlogMaps\"\n",
    "\n",
    "# The census website. NOTE: this URL will have to be updated to 'TIGER2019/' and so on.\n",
    "downloadUrl = \"https://www2.census.gov/geo/tiger/\" + \"TIGER2018/\"\n",
    "\n",
    "# Census download site folder names below\n",
    "#NOTE: if the folder names change on the census download directory for a new year, change the names in this list\n",
    "\n",
    "#folders = ['AIANNH','AITSN','ANRC','BG','CONCITY','COUSUB','CNECTA','CBSA','CD',\n",
    "           #'COUNTY','CSA','CSA','METDIV','NECTA','NECTADIV',\n",
    "           #'PLACE','PUMA','ELSD','SCSD','UNSD','STATE','SLDL','SLDU',\n",
    "           #'SUBMCD','TBG','TRACT','TTRACT','UAC','ZCTA5', \n",
    "           #'AREAWATER','LINEARWATER','COASTLINE',\n",
    "           #'PRIMARYROADS','PRISECROADS','RAILS','ROADS']\n",
    "            \n",
    "#use the list below for testing a couple of folders\n",
    "#uncomment the full list above to download all data folders\n",
    "folders = ['AREAWATER']\n",
    "\n",
    "#print statements are included throughout as checks\n",
    "#uncomment them to run the check, commenting out rest of script\n",
    "\n",
    "for folder in folders:\n",
    "    fullUrl = downloadUrl + folder + \"/\"\n",
    "    #print(fullUrl) \n",
    "    r = requests.get(fullUrl)\n",
    "    webpage = BeautifulSoup(r.text, \"html.parser\")\n",
    "    table = webpage.find(\"table\")\n",
    "    # Find all table row (tr rows)\n",
    "    tr = table.find_all(\"tr\")\n",
    "    #print(tr)\n",
    "    hrefs = []\n",
    "    # Skipping headers\n",
    "    for each_tr in tr[3:]:\n",
    "        td = each_tr.find_all('td')\n",
    "        # In each tr row find each td cell\n",
    "        for each_td in td:\n",
    "            #print(each_td.text) # If you want to check that you are downloading the correct census shapefiles\n",
    "            if each_td.find('a'): hrefs.append(each_td.find('a')['href'])\n",
    "    print(\"Downloading and Extracting files\")\n",
    "    \n",
    "    \n",
    "    for c, h in enumerate(hrefs):\n",
    "        print(\"Downloading %s of %s\" % (c+1, len(hrefs)) )\n",
    "        urlZip = \"%s/%s\" % (fullUrl, h)\n",
    "        theZip = requests.get(urlZip)\n",
    "        try:\n",
    "            z = zipfile.ZipFile(io.BytesIO(theZip.content))\n",
    "            # Creates a file folder to put each type of data into, inside of theShapefileDirectory specified above\n",
    "            if not os.path.exists(os.path.join(theShapeFileDirectory,folder)):\n",
    "                os.makedirs(os.path.join(theShapeFileDirectory,folder))\n",
    "                destination = (os.path.join(theShapeFileDirectory,folder))\n",
    "            # if the file folder with that name already exists, it won't duplicate\n",
    "            else:\n",
    "                destination = (os.path.join(theShapeFileDirectory,folder))\n",
    "            z.extractall(destination)\n",
    "        #if the zipfile is corrupted, it will pass it and continue the script\n",
    "        except BadZipfile:\n",
    "            pass\n",
    "            \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
